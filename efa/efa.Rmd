---
title: EFA
output: pdf_document
---

```{r}
set.seed(42)

library(igraph)
library(moments) # for skewness()
library(robustbase)
library(QuantPsyc) # for the multivariate normality test
library(dunn.test)
library(nFactors) # for the scree plot
library(psych) # for PA FA
library(caret) # highly correlated features removal
library(tidyverse)

library(paletteer) # color palettes

library(conflicted) # to resolve QuantPsyc x dplyr conflicts
conflict_prefer("select", "dplyr")
conflict_prefer("filter", "dplyr")
```

# Load and tidy data

```{r}
pretty_names <- read_csv("../feat_name_mapping.csv")

prettify_feat_name <- function(x) {
  name <- pull(pretty_names %>%
    filter(name_orig == x), name_pretty)
  if (length(name) == 1) {
    return(name)
  } else {
    return(x)
  }
}

prettify_feat_name_vector <- function(x) {
  map(
    x,
    prettify_feat_name
  ) %>% unlist()
}

data <- read_csv("../measurements/measurements.csv")

.firstnonmetacolumn <- 17

data_no_nas <- data %>%
  select(!c(
    fpath,
    # KUK_ID,
    # FileName,
    FolderPath,
    # subcorpus,
    DocumentTitle,
    ClarityPursuit,
    Readability,
    SyllogismBased,
    SourceDB
  )) %>%
  # replace -1s in variation coefficients with NAs
  mutate(across(c(
    `RuleDoubleAdpos.max_allowable_distance.v`,
    `RuleTooManyNegations.max_negation_frac.v`,
    `RuleTooManyNegations.max_allowable_negations.v`,
    `RuleTooManyNominalConstructions.max_noun_frac.v`,
    `RuleTooManyNominalConstructions.max_allowable_nouns.v`,
    `RuleCaseRepetition.max_repetition_count.v`,
    `RuleCaseRepetition.max_repetition_frac.v`,
    `RulePredSubjDistance.max_distance.v`,
    `RulePredObjDistance.max_distance.v`,
    `RuleInfVerbDistance.max_distance.v`,
    `RuleMultiPartVerbs.max_distance.v`,
    `RuleLongSentences.max_length.v`,
    `RulePredAtClauseBeginning.max_order.v`,
    `mattr.v`,
    `maentropy.v`
  ), ~ na_if(.x, -1))) %>%
  # replace NAs with 0s
  replace_na(list(
    RuleGPcoordovs = 0,
    RuleGPdeverbaddr = 0,
    RuleGPpatinstr = 0,
    RuleGPdeverbsubj = 0,
    RuleGPadjective = 0,
    RuleGPpatbenperson = 0,
    RuleGPwordorder = 0,
    RuleDoubleAdpos = 0,
    RuleDoubleAdpos.max_allowable_distance = 0,
    RuleDoubleAdpos.max_allowable_distance.v = 0,
    RuleAmbiguousRegards = 0,
    RuleReflexivePassWithAnimSubj = 0,
    RuleTooManyNegations = 0,
    RuleTooManyNegations.max_negation_frac = 0,
    RuleTooManyNegations.max_negation_frac.v = 0,
    RuleTooManyNegations.max_allowable_negations = 0,
    RuleTooManyNegations.max_allowable_negations.v = 0,
    RuleTooManyNominalConstructions.max_noun_frac.v = 0,
    RuleTooManyNominalConstructions.max_allowable_nouns.v = 0,
    RuleFunctionWordRepetition = 0,
    RuleCaseRepetition.max_repetition_count.v = 0,
    RuleCaseRepetition.max_repetition_frac.v = 0,
    RuleWeakMeaningWords = 0,
    RuleAbstractNouns = 0,
    RuleRelativisticExpressions = 0,
    RuleConfirmationExpressions = 0,
    RuleRedundantExpressions = 0,
    RuleTooLongExpressions = 0,
    RuleAnaphoricReferences = 0,
    RuleLiteraryStyle = 0,
    RulePassive = 0,
    RulePredSubjDistance = 0,
    RulePredSubjDistance.max_distance = 0,
    RulePredSubjDistance.max_distance.v = 0,
    RulePredObjDistance = 0,
    RulePredObjDistance.max_distance = 0,
    RulePredObjDistance.max_distance.v = 0,
    RuleInfVerbDistance = 0,
    RuleInfVerbDistance.max_distance = 0,
    RuleInfVerbDistance.max_distance.v = 0,
    RuleMultiPartVerbs = 0,
    RuleMultiPartVerbs.max_distance = 0,
    RuleMultiPartVerbs.max_distance.v = 0,
    RuleLongSentences.max_length.v = 0,
    RulePredAtClauseBeginning.max_order.v = 0,
    RuleVerbalNouns = 0,
    RuleDoubleComparison = 0,
    RuleWrongValencyCase = 0,
    RuleWrongVerbonominalCase = 0,
    RuleIncompleteConjunction = 0
  ))
```

## Outliers

```{r}
data_no_out <- data_no_nas %>% filter(KUK_ID != "CzCDC_SupC088540")
```

## Normalization

```{r}
data_clean <- data_no_out %>%
  # norm data expected to correlate with text length
  mutate(across(c(
    RuleGPcoordovs,
    RuleGPdeverbaddr,
    RuleGPpatinstr,
    RuleGPdeverbsubj,
    RuleGPadjective,
    RuleGPpatbenperson,
    RuleGPwordorder,
    RuleDoubleAdpos,
    RuleAmbiguousRegards,
    RuleFunctionWordRepetition,
    RuleWeakMeaningWords,
    RuleAbstractNouns,
    RuleRelativisticExpressions,
    RuleConfirmationExpressions,
    RuleRedundantExpressions,
    RuleTooLongExpressions,
    RuleAnaphoricReferences,
    RuleLiteraryStyle,
    RulePassive,
    RuleVerbalNouns,
    RuleDoubleComparison,
    RuleWrongValencyCase,
    RuleWrongVerbonominalCase,
    RuleIncompleteConjunction,
    num_hapax,
    RuleReflexivePassWithAnimSubj,
    RuleTooManyNominalConstructions,
    RulePredSubjDistance,
    RuleMultiPartVerbs,
    RulePredAtClauseBeginning
  ), ~ .x / word_count)) %>%
  mutate(across(c(
    RuleTooFewVerbs,
    RuleTooManyNegations,
    RuleCaseRepetition,
    RuleLongSentences,
    RulePredObjDistance,
    RuleInfVerbDistance
  ), ~ .x / sent_count)) %>%
  # remove variables identified as "u counts"
  select(!c(
    RuleTooFewVerbs,
    RuleTooManyNegations,
    RuleTooManyNominalConstructions,
    RuleCaseRepetition,
    RuleLongSentences,
    RulePredAtClauseBeginning,
    syllab_count,
    char_count
  )) %>%
  # remove variables identified as unreliable
  select(!c(
    RuleAmbiguousRegards,
    RuleFunctionWordRepetition,
    RuleDoubleComparison,
    RuleWrongValencyCase,
    RuleWrongVerbonominalCase
  )) %>%
  # remove artificially limited variables
  select(!c(
    RuleCaseRepetition.max_repetition_frac,
    RuleCaseRepetition.max_repetition_frac.v
  )) %>%
  # remove further variables belonging to the 'acceptability' category
  select(!c(RuleIncompleteConjunction)) %>%
  mutate(across(c(
    class,
    FileFormat,
    subcorpus,
    DocumentVersion,
    LegalActType,
    Objectivity,
    AuthorType,
    RecipientType,
    RecipientIndividuation,
    Anonymized
  ), ~ as.factor(.x)))

# no NAs should be present now
data_clean[!complete.cases(data_clean), ]

data_clean_scaled <- data_clean %>%
  mutate(across(class, ~ .x == "good")) %>%
  mutate(across(.firstnonmetacolumn:length(names(data_clean)), ~ scale(.x)))
```

# Important features identification

```{r}
feature_importances <- tibble(
  feat_name = character(), p_value = numeric()
)

for (i in .firstnonmetacolumn:ncol(data_clean)) {
  fname <- names(data_clean)[i]

  formula_single <- reformulate(fname, "class")

  glm_model <- glm(formula_single, data_clean, family = "binomial")
  glm_coefficients <- summary(glm_model)$coefficients
  row_index <- which(rownames(glm_coefficients) == fname)
  p_value <- glm_coefficients[row_index, 4]

  feature_importances <- feature_importances %>%
    add_row(feat_name = fname, p_value = p_value)
}
feature_importances

selected_features <- feature_importances %>%
  mutate(selected = p_value <= 0.05)
selected_features %>% write_csv("selected_features.csv")
selected_features_names <- selected_features %>%
  filter(selected) %>%
  pull(feat_name)

data_purish <- data_clean %>% select(any_of(selected_features_names))
colnames(data_purish) <- prettify_feat_name_vector(colnames(data_purish))
```

# Skewness

```{r}
.absskewnesscutoff <- 5
.absmedcouplecutoff <- 0.5

medc <- numeric()
sk <- numeric()
for (i in seq_along(colnames(data_purish))) {
  d <- as.vector(data_purish[i])[[1]]
  medc <- c(medc, mc(d, doScale = TRUE))
  sk <- c(sk, skewness(d))
}

data_skewness <- data.frame(
  feat = colnames(data_purish), medcouple = medc, skewness = sk
)

data_skewness %>%
  ggplot(aes(x = medcouple, y = feat, label = medcouple %>% round(3))) +
  geom_col() +
  geom_label()

data_skewness %>%
  ggplot(aes(x = skewness, y = feat, label = skewness %>% round(3))) +
  geom_col() +
  geom_label()

data_skewness %>%
  ggplot(aes(
    x = skewness, y = medcouple, label = feat,
    color = abs(skewness) < .absskewnesscutoff &
      abs(medcouple) < .absmedcouplecutoff
  )) +
  geom_text() +
  theme(legend.position = "bottom")

acceptably_skewed <- data_skewness %>%
  filter(abs(skewness) < .absskewnesscutoff &
    abs(medcouple) < .absmedcouplecutoff) %>%
  pull(feat)
acceptably_skewed

data_unskewed <- data_purish %>% select(any_of(acceptably_skewed))

# pairs.panels(data_unskewed, lm = TRUE)
```

# Correlations

See Levshina (2015: 353--54).

```{r}
analyze_correlation <- function(data) {
  cor_matrix <- cor(data)

  cor_tibble_long <- cor_matrix %>%
    as_tibble() %>%
    mutate(feat1 = rownames(cor_matrix)) %>%
    pivot_longer(!feat1, names_to = "feat2", values_to = "cor") %>%
    mutate(abs_cor = abs(cor))

  cor_matrix_upper <- cor_matrix
  cor_matrix_upper[lower.tri(cor_matrix_upper)] <- 0

  cor_tibble_long_upper <- cor_matrix_upper %>%
    as_tibble() %>%
    mutate(feat1 = rownames(cor_matrix)) %>%
    pivot_longer(!feat1, names_to = "feat2", values_to = "cor") %>%
    mutate(abs_cor = abs(cor)) %>%
    filter(feat1 != feat2 & abs_cor > 0)

  list(
    cor_matrix = cor_matrix,
    cor_matrix_upper = cor_matrix_upper,
    cor_tibble_long = cor_tibble_long,
    cor_tibble_long_upper = cor_tibble_long_upper
  )
}


# data_purish <- data_clean %>% select(any_of(selected_features_names)) %>%
#   # remove features expected to have low communalities
#   select(!c(
#     RuleDoubleAdpos.max_allowable_distance,
#     RuleDoubleAdpos.max_allowable_distance.v,
#     RuleGPwordorder,
#     RuleLiteraryStyle,
#     maentropy.v,
#     RuleTooManyNegations.max_negation_frac,
#     RulePredSubjDistance.max_distance,
#     RuleTooManyNegations.max_allowable_negations,
#     RuleTooManyNegations.max_allowable_negations.v,
#     RuleTooManyNominalConstructions.max_allowable_nouns.v,
#     RuleTooFewVerbs.min_verb_frac.v,
#     RulePredObjDistance.max_distance.v,
#     RulePredObjDistance.max_distance,
#     RulePredAtClauseBeginning.max_order.v,
#     RuleInfVerbDistance
#   )) %>%
#   # remove features expected to have low loadings
#   select(!c(
#     RuleMultiPartVerbs.max_distance.v,
#     RulePredSubjDistance.max_distance.v,
#     RuleLongSentences.max_length
#   ))
```

## Extremely non-normal data

```{r}
# # remove where median == 0?
# keep <- character()
# for (i in seq_along(colnames(data_purish))) {
#   cname <- colnames(data_purish)[i]
#   q <- quantile(data_purish[, i][[1]], probs = 0.10)[[1]]
#   if (q > 0) {
#     keep <- c(keep, cname)
#     cat("keep", cname, "\n")
#   } else {
#     cat("throw out", cname, "\n")
#   }
# }
# data_purish <- data_purish %>% select(any_of(keep))
```

## High correlations

```{r}
.hcorrcutoff <- 0.7

library(corrplot)
corrplot(cor(data_unskewed), method = "color", tl.cex = 0.6)

analyze_correlation(data_purish)$cor_tibble_long %>%
  filter(feat1 != feat2 & abs_cor > .hcorrcutoff) %>%
  arrange(feat1, -abs_cor) %>%
  print(n = 100)
```

exclude: 

- **ari:** corr. w/ RuleLongSentences.max_length > 0.94; sentence length seems more universal, let's make it a substitute 
- **gf:** corr. w/ RuleLongSentences.max_length > 0.92; sentence length seems more universal, let's make it a substitute
- **maentropy:** corr. w/ mattr > 0.96, but mattr is implemented in QuitaUp. besides, the interesting thing about maentropy is its variation
- **smog:** corr. w/ fkgl almost 0.95, but fkgl coefficients adjusted for Czech are available
- **atl:** corr. w/ cli around 0.96; unlike cli, atl is not a readability metric

```{r}
high_correlations <- findCorrelation(
  cor(data_purish),
  verbose = TRUE, cutoff = .hcorrcutoff
)
names(data_purish)[high_correlations]

data_pureish_striphigh <- data_purish %>% select(!all_of(high_correlations))

analyze_correlation(data_pureish_striphigh)$cor_tibble_long %>%
  filter(feat1 != feat2 & abs_cor > .hcorrcutoff) %>%
  arrange(feat1, -abs_cor) %>%
  print(n = 100)
```

## Low correlations

```{r}
.lcorrcutoff <- 0.4

low_correlating_features <- analyze_correlation(data_pureish_striphigh)$
  cor_tibble_long %>%
  filter(feat1 != feat2) %>%
  group_by(feat1) %>%
  summarize(max_cor = max(abs_cor)) %>%
  filter(max_cor < .lcorrcutoff) %>%
  pull(feat1)

feature_importances %>% filter(feat_name %in% low_correlating_features)

data_pure <- data_pureish_striphigh %>%
  select(!any_of(low_correlating_features))

colnames(data_pure) <- prettify_feat_name_vector(colnames(data_pure))

corrplot(cor(data_pure), method = "color", tl.cex = 0.6)
corrplot(cor(data_pure) %>% abs(), method = "color", tl.cex = 0.6)
```

# Verbalness FA

```{r}
# data_verbalness <- data_pure %>%
#   select(VERBfrac.m, NOUNcount.m, activity, verbdist) %>%
#   # mutate(neg.NOUNcount.m = -NOUNcount.m, neg.verbdist = -verbdist) %>%
#   # select(!c(NOUNcount.m, verbdist)) %>%
#   mutate(across(VERBfrac.m:verbdist, ~ scale(.x)[, 1]))

# corrplot(cor(data_verbalness), method = "color", tl.cex = 0.6)

# data_verbalness %>%
#   cor() %>%
#   det()
# KMO(data_verbalness)

# mult.norm(data_verbalness %>% as.data.frame())$mult.test

# fa.parallel(data_verbalness, fm = "pa", fa = "fa", n.iter = 20)

# fa_verbalness <- fa(
#   data_verbalness,
#   nfactors = 2,
#   fm = "pa",
#   rotate = "promax",
#   oblique.scores = TRUE,
#   scores = "tenBerge",
#   n.iter = 100
# )
# fa_verbalness

# data_verbalness_parcels <- data_verbalness %>%
#   rowid_to_column("ID") %>%
#   pivot_longer(!ID, names_to = "name", values_to = "value") %>%
#   group_by(ID) %>%
#   summarize(
#     verbalness = weighted.mean(value, fa_verbalness$loadings[, "PA1"]),
#     nominalness = weighted.mean(value, fa_verbalness$loadings[, "PA2"])
#   ) %>%
#   ungroup() %>%
#   select(!ID)

# data_pure <- data_pure %>%
#   bind_cols(data_verbalness_parcels) %>%
#   select(!c(VERBfrac.m, NOUNcount.m, activity, verbdist))
```

# Correlation matrix determinant

determinants > 0.00001 = 1e-5 generally indicate multicollinearity is probably not a problem (Watkins 2021: 61).

```{r}
data_pure %>%
  cor() %>%
  det() %>%
  print(digits = 5)
```

# Bartlett's test of sphericity

null hypothesis: the correlation matrix is an identity matrix, i.e. random. sensitive to sample size, should be considered a minimal standard (Watkins 2021: 61).

```{r}
cortest.bartlett(data_pure)
```

# Kaiser-Meyer-Olkin measure of sampling adequacy

there are debates about which values KMO values are acceptable. Kaiser (1974) suggested that KMO < .50 are unacceptable but other measurement specialists recomment a minimum value of .60 for acceptability with values >= .70 preferred (Watkins 2021: 61).

```{r}
KMO(data_pure)
```

# Visualisation

```{r fig.width=12, fig.height=12, fig.align='center'}
my_colors <- paletteer::paletteer_d("ggthemes::Classic_10_Medium")

network_edges <- analyze_correlation(data_pure)$cor_tibble_long_upper %>%
  filter(abs_cor > .lcorrcutoff)

network <- graph_from_data_frame(
  network_edges,
  directed = FALSE
)
E(network)$weight <- network_edges$abs_cor
network_communities <- cluster_optimal(network)

network_membership <- membership(network_communities)

plot(
  network,
  layout = layout.fruchterman.reingold,
  vertex.color = map(
    network_communities$membership,
    function(x) my_colors[x]
  ) %>% unlist(use.names = FALSE),
  vertex.size = 6,
  vertex.label.color = "black",
  vertex.label.cex = 0.7
)
```

# Scaling

```{r}
data_scaled <- data_pure %>%
  mutate(across(seq_along(data_pure), ~ scale(.x)[, 1]))

final_collist <- data_scaled %>% colnames()
```

# Check for normality

```{r}
mult.norm(data_scaled %>% as.data.frame())$mult.test
```

Low (null) p-values show that we can reject the hypothesis that the data would be in a multivariate normal distribution. I.e. the distribution isn't multivariate normal.

# FA

## No. of factors

```{r}
eigen <- eigen(cor(data_scaled))
par <- nFactors::parallel(
  subject = nrow(data_scaled),
  var = ncol(data_scaled),
  rep = 100,
  quantile = .95,
  model = "factors"
)
scree <- nScree(x = eigen$values, aparallel = par$eigen$qevpea)
plotnScree(scree)

fa.parallel(data_scaled, fm = "pa", fa = "fa", n.iter = 20)
```

## Model

<https://www.rdocumentation.org/packages/psych/versions/2.5.3/topics/fa>

```{r}
# appears to be the happiest when nfactors = 6 or 7
# throws the The estimated weights for the factor scores are probably incorrect.
# Try a different factor score estimation method. warning otherwise
fa_res <- fa(
  data_scaled,
  nfactors = 7,
  fm = "pa",
  rotate = "promax",
  oblique.scores = TRUE,
  scores = "tenBerge",
  n.iter = 100
)
fa_res
```

### Loadings

```{r}
fa_res$loadings

for (i in 1:fa_res$factors) {
  cat("\n-----", colnames(fa_res$loadings)[i], "-----\n")

  loadings <- fa_res$loadings[, i]
  load_df <- data.frame(loading = loadings)

  load_df_filtered <- load_df %>%
    mutate(abs_l = abs(loading)) %>%
    mutate(str = case_when(
      abs_l > 0.7 ~ "***",
      abs_l <= 0.7 & abs_l > 0.5 ~ "** ",
      abs_l <= 0.5 & abs_l > 0.3 ~ "*  ",
      abs_l <= 0.3 & abs_l > 0.1 ~ ".  ",
      .default = ""
    )) %>%
    arrange(-abs_l) %>%
    filter(abs_l > 0.1)

  load_df_filtered %>%
    mutate(across(c(loading, abs_l), ~ round(.x, 3))) %>%
    print()

  cat("\n")
}
```

hypotheses:

- **PA1:** register – narrativity, richness of expression; shorter clauses (-technical / +narrative)
  - narrativity? (1st and 2nd persons etc.)
- **PA2:** text length (-short / +long)
  - hapaxes load negatively, because I normed them over word count
- **PA6:** sentence complexity (more clauses) (-simple / +complex)
  - slightly longer nominal constructions / more objects, more years of education necessary, predicates slightly further in the clause, slightly more verbs
  - `fkgl` in strong correlation with `sentlen.m`
- **PA3:** word length (-short / +long)
  - cli highly correlates with atl, meaning the factor likely expresses mostly token lengths
  - slightly more passives, slightly more objects, slightly less verbal overall / slightly longer nom. constructions, slightly morphologically richer, many years of education necessary
  - more enumerations? but one would expect higher `activity` differences to occur if that was the case
- **PA4:** lexical richness (-poor / +rich)
- **PA5:** passivity (-active / +passive)
  - compound verbs, because that's what passives are in Czech
  - smaller activity, because passive participles count as `ADJ` in UD.
- **PA7:** compound verbs (-less / +more)

strong correlations:

- **PA1–PA6:** (-0.38) narrativity leads to simple clauses
- **PA2–PA6:** (+0.30) longer texts include more complex sentences
- **PA1–PA5:** (-0.49, topconf = +0.09) narrative texts more active

> **NOTE:** variables with low communalities are excluded from the analysis, yet still likely play a role in legal writing readability. this includes both those selected for the analysis and the excluded ones.
>
> **NOTE:** some high-correlating variables were excluded from the FA.

### Healthiness diagnostics

```{r}
fa_res$loadings[] %>%
  as_tibble() %>%
  mutate(feat = colnames(data_scaled)) %>%
  select(feat, everything()) %>%
  pivot_longer(!feat) %>%
  mutate(value = abs(value)) %>%
  group_by(feat) %>%
  summarize(maxload = max(value)) %>%
  arrange(maxload)

fa_res$communality %>% sort()
```

### Uniquenesses

```{r}
fa_res$uniquenesses %>% round(3)
```

## Distributions over factors

```{r, fig.height=8}
analyze_distributions <- function(data_factors_long, variable) {
  plot <- data_factors_long %>%
    ggplot(aes(x = factor_score, y = !!sym(variable))) +
    geom_boxplot() +
    facet_grid(factor ~ .)
  print(plot)

  formula <- reformulate(variable, "factor_score")
  factors <- levels(data_factors_long$factor)

  min_p_values <- numeric()
  for (f in factors) {
    data <- data_factors_long %>% filter(factor == f)

    cat(
      "\nTest for the significance of differences in",
      variable, "over", f, ":\n\n"
    )

    dunn <- dunn.test(
      data$factor_score, data[[variable]],
      altp = TRUE, method = "bonferroni"
    )
    min_p_values <- c(min_p_values, min(dunn$altP.adjusted))
  }

  cat(
    "\np < 5e-2\tfound in:",
    factors[min_p_values < 0.05],
    "\np < 1e-2\tfound in:",
    factors[min_p_values < 0.01],
    "\np < 1e-3\tfound in:",
    factors[min_p_values < 0.001],
    "\np < 1e-4\tfound in:",
    factors[min_p_values < 0.0001], "\n"
  )
}

data_factors <- bind_cols(data_pure, fa_res$scores %>% as.data.frame())
colnames(data_factors) <- prettify_feat_name_vector(colnames(data_factors))

data_factors_noout <- bind_cols(data_no_out, fa_res$scores %>% as.data.frame())
colnames(data_factors_noout) <- prettify_feat_name_vector(
  colnames(data_factors_noout)
)

data_factors_long <- data_factors %>%
  pivot_longer(PA1:PA4, names_to = "factor", values_to = "factor_score") %>%
  mutate(across(
    factor,
    ~ factor(.x, levels = c("PA1", "PA2", "PA6", "PA3", "PA4", "PA5", "PA7"))
  ))

data_factors_noout_long <- data_factors_noout %>%
  pivot_longer(PA1:PA4, names_to = "factor", values_to = "factor_score") %>%
  mutate(across(
    factor,
    ~ factor(.x, levels = c("PA1", "PA2", "PA6", "PA3", "PA4", "PA5", "PA7"))
  ))

data_factors_noout_long %>%
  ggplot(aes(x = factor_score, y = class)) +
  facet_grid(factor ~ .) +
  theme(legend.position = "bottom") +
  geom_jitter(width = 0, height = 0.1, alpha = 0.2)
```

### class

```{r}
analyze_distributions(data_factors_noout_long, "class")
```

### subcorpus

```{r}
analyze_distributions(data_factors_noout_long, "subcorpus")
```

### subcorpus wo/ LiFRLaw

```{r}
analyze_distributions(
  data_factors_noout_long %>% filter(subcorpus != "LiFRLaw"), "subcorpus"
)
```

### AuthorType

```{r}
analyze_distributions(data_factors_noout_long, "AuthorType")
```

### RecipientType

```{r}
analyze_distributions(data_factors_noout_long, "RecipientType")
```

court decisions often with `RecipientType = combined`.

### RecipientIndividuation

```{r}
analyze_distributions(data_factors_noout_long, "RecipientIndividuation")
```

### Objectivity

```{r}
analyze_distributions(data_factors_noout_long, "Objectivity")
```

### Bindingness

```{r}
analyze_distributions(data_factors_noout_long, "Bindingness")
```

# Feature-factor correlations

```{r}
data_factors_clean_longer <- data_factors_noout_long %>%
  pivot_longer(
    abstractNOUNs:verbdist,
    names_to = "feat", values_to = "feat_value"
  )

data_factors_correlations <- data_factors_clean_longer %>%
  group_by(feat, factor) %>%
  summarize(correlation = cor(feat_value, factor_score))

data_factors_correlations %>%
  filter(feat %in% final_collist) %>%
  ggplot(aes(
    x = factor,
    y = feat,
    fill = correlation,
    label = round(correlation, 2)
  )) +
  geom_tile() +
  geom_text() +
  scale_fill_gradient2()
```

```{r fig.height=9}
data_factors_correlations %>%
  filter(!(feat %in% final_collist)) %>%
  ggplot(aes(
    x = factor,
    y = feat,
    fill = correlation,
    label = round(correlation, 2)
  )) +
  geom_tile() +
  geom_text() +
  scale_fill_gradient2()
```